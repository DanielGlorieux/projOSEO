#!/usr/bin/env python3
"""
Script de v√©rification GPU pour entra√Ænement
V√©rifie que PyTorch peut utiliser le GPU
"""
import torch
import sys

def check_gpu():
    """V√©rifie disponibilit√© GPU et configuration"""
    print("="*60)
    print("üîç V√âRIFICATION CONFIGURATION GPU")
    print("="*60)
    
    # Version PyTorch
    print(f"\nüì¶ PyTorch Version: {torch.__version__}")
    
    # CUDA disponible?
    cuda_available = torch.cuda.is_available()
    print(f"\nüéÆ CUDA Disponible: {'‚úÖ OUI' if cuda_available else '‚ùå NON'}")
    
    if cuda_available:
        # D√©tails GPU
        print(f"\nüñ•Ô∏è  GPU D√©tect√©:")
        print(f"  - Nombre de GPUs: {torch.cuda.device_count()}")
        print(f"  - GPU Actif: {torch.cuda.current_device()}")
        print(f"  - Nom GPU: {torch.cuda.get_device_name(0)}")
        
        # M√©moire GPU
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"  - M√©moire totale: {total_memory:.2f} GB")
        
        # Version CUDA
        print(f"\nüîß CUDA Version: {torch.version.cuda}")
        print(f"üîß cuDNN Version: {torch.backends.cudnn.version()}")
        
        # Test simple
        print("\nüß™ Test Calcul GPU:")
        try:
            x = torch.randn(1000, 1000).cuda()
            y = torch.randn(1000, 1000).cuda()
            z = torch.matmul(x, y)
            print("  ‚úÖ Calcul GPU fonctionnel!")
            
            # Test performance
            import time
            start = time.time()
            for _ in range(100):
                z = torch.matmul(x, y)
            torch.cuda.synchronize()
            gpu_time = time.time() - start
            print(f"  ‚ö° Performance: {gpu_time:.4f}s pour 100 multiplications matricielles")
            
        except Exception as e:
            print(f"  ‚ùå Erreur calcul GPU: {e}")
            return False
            
        # Recommandations
        print("\n‚úÖ CONFIGURATION OPTIMALE D√âTECT√âE!")
        print("üìä Configuration entra√Ænement recommand√©e:")
        print(f"  - Batch size: 256 (GPU) vs 32 (CPU)")
        print(f"  - Workers: 4")
        print(f"  - Mixed precision: Activ√©e")
        print(f"  - Acc√©l√©ration attendue: 5-8x")
        
        return True
        
    else:
        print("\n‚ö†Ô∏è  GPU NON D√âTECT√â - Mode CPU")
        print("\nüîç Diagnostics:")
        print("  1. V√©rifiez nvidia-smi:")
        print("     $ nvidia-smi")
        print("  2. V√©rifiez CUDA install√©:")
        print("     $ nvcc --version")
        print("  3. R√©installez PyTorch GPU:")
        print("     $ pip install torch==2.1.2+cu118 --index-url https://download.pytorch.org/whl/cu118")
        
        return False

def check_dependencies():
    """V√©rifie autres d√©pendances critiques"""
    print("\n" + "="*60)
    print("üì¶ V√âRIFICATION D√âPENDANCES")
    print("="*60)
    
    required_packages = [
        'numpy',
        'pandas',
        'scikit-learn',
        'stable_baselines3',
        'gymnasium'
    ]
    
    all_ok = True
    for package in required_packages:
        try:
            __import__(package)
            print(f"  ‚úÖ {package}")
        except ImportError:
            print(f"  ‚ùå {package} - MANQUANT!")
            all_ok = False
    
    return all_ok

if __name__ == "__main__":
    print("\nüöÄ ONEA HACKATHON - V√©rification Environnement GPU\n")
    
    gpu_ok = check_gpu()
    deps_ok = check_dependencies()
    
    print("\n" + "="*60)
    if gpu_ok and deps_ok:
        print("‚úÖ SYST√àME PR√äT POUR ENTRA√éNEMENT GPU!")
        print("="*60)
        print("\nüéØ Commandes suivantes:")
        print("  $ python3 scripts/train_models.py --station OUG_ZOG --models all")
        print("\n‚ö° Attendez-vous √† 5-8x plus rapide qu'en CPU!")
        sys.exit(0)
    elif not gpu_ok and deps_ok:
        print("‚ö†Ô∏è  MODE CPU - Entra√Ænement possible mais lent")
        print("="*60)
        print("\nüí° Installez CUDA et PyTorch GPU pour acc√©l√©ration")
        sys.exit(1)
    else:
        print("‚ùå D√âPENDANCES MANQUANTES")
        print("="*60)
        print("\nüîß Installez les d√©pendances:")
        print("  $ pip install -r requirements-gpu-linux.txt")
        sys.exit(1)
